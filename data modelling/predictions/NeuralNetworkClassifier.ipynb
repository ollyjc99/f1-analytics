{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "if platform == \"win32\":\n",
    "    path = 'C:/Users/olive/GitHub/f1-analytics/'\n",
    "elif platform == \"darwin\":\n",
    "    path = '~/Documents/GitHub/f1-analytics/'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path+'data/ml_input.csv')\n",
    "merged = pd.read_csv(path+'data/merged.csv')\n",
    "parameters = pd.read_csv(path+'parameters/neutralnetworkclassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Season to test results\n",
    "\n",
    "N = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'round', 'podium', 'driver_points', 'driver_wins',\n",
       "       'driver_standings_pos', 'constructor_wins_after_race',\n",
       "       'constructor_points', 'constructor_wins', 'constructor_standings_pos',\n",
       "       'average_pace', 'grid', 'qual_time', 'circuit_id_albert_park',\n",
       "       'circuit_id_americas', 'circuit_id_bahrain', 'circuit_id_baku',\n",
       "       'circuit_id_catalunya', 'circuit_id_hockenheimring',\n",
       "       'circuit_id_hungaroring', 'circuit_id_imola', 'circuit_id_interlagos',\n",
       "       'circuit_id_istanbul', 'circuit_id_jeddah', 'circuit_id_losail',\n",
       "       'circuit_id_marina_bay', 'circuit_id_monaco', 'circuit_id_monza',\n",
       "       'circuit_id_mugello', 'circuit_id_nurburgring', 'circuit_id_portimao',\n",
       "       'circuit_id_red_bull_ring', 'circuit_id_ricard', 'circuit_id_rodriguez',\n",
       "       'circuit_id_sepang', 'circuit_id_shanghai', 'circuit_id_silverstone',\n",
       "       'circuit_id_sochi', 'circuit_id_spa', 'circuit_id_suzuka',\n",
       "       'circuit_id_villeneuve', 'circuit_id_yas_marina',\n",
       "       'circuit_id_zandvoort', 'stage_q1', 'stage_q2', 'stage_q3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df.podium = df.podium.map(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "train = df[df.season != N]\n",
    "X_train = train.drop(['podium', 'average_pace'], axis=1)\n",
    "y_train = train.podium\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_classification(model):\n",
    "    score = 0\n",
    "    for circuit in df[df.season == N]['round'].unique():\n",
    "\n",
    "        test = df[(df.season == N) & (df['round'] == circuit)]\n",
    "        X_test = test.drop(['podium', 'average_pace'], axis = 1)\n",
    "        y_test = test.podium\n",
    "        \n",
    "        #scaling\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "        # make predictions\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['proba_0', 'proba_1'])\n",
    "        prediction_df['actual'] = y_test.reset_index(drop=True)\n",
    "        prediction_df.sort_values('proba_1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace=True, drop=True)\n",
    "        prediction_df['predicted'] = prediction_df.index\n",
    "        prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "        score += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "\n",
    "    model_score = score / df[df.season == N]['round'].unique().max()\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict ={'model':[],\n",
    "                  'hidden_layer_sizes': [],\n",
    "                  'activation': [],\n",
    "                  'solver': [],\n",
    "                  'alpha': [],\n",
    "                  'score': []\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "\n",
    "params={'hidden_layer_sizes': [(80,20,40,5), (75,25,50,10)], \n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "        'solver': ['lbfgs', 'sgd', 'adam'], \n",
    "        'alpha': np.logspace(-4,2,20)} \n",
    "\n",
    "parms = parameters\n",
    "\n",
    "\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    for activation in params['activation']:\n",
    "        for solver in params['solver']:\n",
    "            for alpha in params['alpha']:\n",
    "                model_params = (hidden_layer_sizes, activation, solver, alpha)\n",
    "                model = MLPClassifier(\n",
    "                    hidden_layer_sizes=hidden_layer_sizes,\n",
    "                    activation=activation, \n",
    "                    solver=solver, alpha=alpha, \n",
    "                    random_state=1)\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                model_score = score_classification(model)\n",
    "\n",
    "                comparison_dict['model'].append('neural_network_classifier')\n",
    "                comparison_dict['hidden_layer_sizes'].append(hidden_layer_sizes)\n",
    "                comparison_dict['activation'].append(activation)\n",
    "                comparison_dict['solver'].append(solver)\n",
    "                comparison_dict['alpha'].append(alpha)\n",
    "                comparison_dict['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>alpha</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, hidden_layer_sizes, activation, solver, alpha, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame(comparison_dict)\n",
    "\n",
    "comparison_df.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_inputs = comparison_df.query('score == 0.7272727272727273')\n",
    "\n",
    "# chosen_inputs.to_csv(path+'parameters/neutralnetworkclassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>alpha</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>(80, 20, 40, 5)</td>\n",
       "      <td>identity</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      model hidden_layer_sizes activation solver  \\\n",
       "0           0  neural_network_classifier    (80, 20, 40, 5)   identity  lbfgs   \n",
       "\n",
       "    alpha     score  \n",
       "0  0.0001  0.727273  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model):\n",
    "    predictions = []\n",
    "    for circuit in df[df.season == N]['round'].unique():\n",
    "\n",
    "        test = df[(df.season == N) & (df['round'] == circuit)]\n",
    "        X_test = test.drop(['podium', 'average_pace'], axis = 1)\n",
    "        y_test = test.podium\n",
    "        \n",
    "        #scaling\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "        # make predictions\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns=['proba_0', 'proba_1'])\n",
    "        prediction_df['actual'] = y_test.reset_index(drop=True)\n",
    "        # prediction_df.sort_values('proba_1', ascending=False, inplace=True)\n",
    "        # prediction_df.reset_index(inplace=True, drop=True)\n",
    "        # prediction_df['predicted'] = prediction_df.proba_1.map(lambda x: 1 if x == prediction_df.proba_1.max() else x)\n",
    "\n",
    "        predictions += list(prediction_df.proba_1.values)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes= [(80,20,40,5), (75, 25, 50, 10)][0]\n",
    "activation='identity'\n",
    "solver='lbfgs'\n",
    "alpha=0.00001\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation, \n",
    "    solver=solver, alpha=alpha, \n",
    "    random_state=1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model_score = score_classification(model)\n",
    "predictions = get_predictions(model)\n",
    "\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = merged.query('season ==@N')\n",
    "test['predict'] = predictions\n",
    "test = test[['season', 'round', 'circuit_id', 'driver', 'grid', 'podium', 'predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>circuit_id</th>\n",
       "      <th>driver</th>\n",
       "      <th>grid</th>\n",
       "      <th>podium</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>baku</td>\n",
       "      <td>perez</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8.575517e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>baku</td>\n",
       "      <td>vettel</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8.342354e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>baku</td>\n",
       "      <td>gasly</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.987501e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>baku</td>\n",
       "      <td>leclerc</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960982e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>baku</td>\n",
       "      <td>norris</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.043530e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>perez</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4.375353e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>latifi</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.992979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>giovinazzi</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>7.446177e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>russell</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1.454042e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>raikkonen</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1.678788e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season  round  circuit_id      driver  grid  podium       predict\n",
       "2379    2021      6        baku       perez     7       1  8.575517e-02\n",
       "2380    2021      6        baku      vettel    11       2  8.342354e-09\n",
       "2381    2021      6        baku       gasly     4       3  1.987501e-06\n",
       "2382    2021      6        baku     leclerc     1       4  1.960982e-06\n",
       "2383    2021      6        baku      norris     6       5  1.043530e-07\n",
       "...      ...    ...         ...         ...   ...     ...           ...\n",
       "2675    2021     22  yas_marina       perez     4      15  4.375353e-02\n",
       "2676    2021     22  yas_marina      latifi    16      16  1.992979e-06\n",
       "2677    2021     22  yas_marina  giovinazzi    14      17  7.446177e-09\n",
       "2678    2021     22  yas_marina     russell    17      18  1.454042e-06\n",
       "2679    2021     22  yas_marina   raikkonen    18      19  1.678788e-06\n",
       "\n",
       "[301 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
